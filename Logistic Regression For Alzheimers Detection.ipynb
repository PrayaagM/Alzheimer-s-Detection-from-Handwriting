{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Alzheimer's from Features of Handwriting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We aim to train a neural network to use Logistic Regression to classify handwriting samples as belonging to a patient with Alzheimer's or not. The training and testing dataset we use is the DARWIN Dataset created by Francesco Fontanella.\n",
    "\n",
    "### Source: https://archive.ics.uci.edu/dataset/732/darwin\n",
    "### Kaggle Link: https://www.kaggle.com/datasets/taeefnajib/handwriting-data-to-detect-alzheimers-disease/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We do the above in 3 Main Steps:\n",
    "\n",
    "### Step 1) - Design the Model ( Input Size, Output Size, Activation Functions, Hidden Layers ) -- Forward Propagation\n",
    "### Step 2) - Create Optimizer, choose Loss function ( Binary Cross Entropy Loss since this is a classification problem )\n",
    "### Step 3) - Training Loop -- Backwards Propagation -- Calculate Gradients (Stochastic Gradient Descent), Calculate Loss, Update Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 0 -- Readying the Data ###\n",
    "pd.options.mode.copy_on_write = True # Enabling Copy on Write so mutations to copies of df do not mutate df.\n",
    "df = pd.read_csv('./data.csv').drop(labels=['ID'], axis=1)\n",
    "\n",
    "X_data = df.drop(labels=['class'], axis = 1, inplace=False)\n",
    "Y_data = df['class']\n",
    "\n",
    "for row in range(len(Y_data)):\n",
    "    if (Y_data[row] == 'P'): Y_data[row] = 1\n",
    "    elif (Y_data[row] == 'H'): Y_data[row] = 0\n",
    "\n",
    "\n",
    "X_data = X_data.to_numpy().astype(np.float32)\n",
    "Y_data = Y_data.to_numpy().astype(np.float32)\n",
    "\n",
    "n_samples, n_features = X_data.shape # 174 x 450 (174 samples, 450 features)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=1234)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "\n",
    "Y_train = torch.from_numpy(Y_train)\n",
    "Y_test = torch.from_numpy(Y_test)\n",
    "\n",
    "Y_train = Y_train.view(Y_train.shape[0], 1)\n",
    "Y_test = Y_test.view(Y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # f = sigmoid(w*x + b)\n",
    "        return torch.sigmoid(self.linear(X))\n",
    "\n",
    "model = LogisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer ( What does thra gradient calculations ) + Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2) - Getting Loss function and Optimizer\n",
    "# Using Binary Cross Entropy Loss & Stochastic Gradient Descent\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, loss = 0.8327412605285645\n",
      "epoch = 10, loss = 0.4486154317855835\n",
      "epoch = 20, loss = 0.35812291502952576\n",
      "epoch = 30, loss = 0.30859440565109253\n",
      "epoch = 40, loss = 0.27473074197769165\n",
      "epoch = 50, loss = 0.2493411898612976\n",
      "epoch = 60, loss = 0.2292877584695816\n",
      "epoch = 70, loss = 0.21288810670375824\n",
      "epoch = 80, loss = 0.1991301327943802\n",
      "epoch = 90, loss = 0.1873588263988495\n",
      "epoch = 100, loss = 0.1771279275417328\n",
      "epoch = 110, loss = 0.16812138259410858\n",
      "epoch = 120, loss = 0.16010817885398865\n",
      "epoch = 130, loss = 0.1529151052236557\n",
      "epoch = 140, loss = 0.1464092880487442\n",
      "epoch = 150, loss = 0.14048689603805542\n",
      "epoch = 160, loss = 0.13506537675857544\n",
      "epoch = 170, loss = 0.1300780177116394\n",
      "epoch = 180, loss = 0.12547031044960022\n",
      "epoch = 190, loss = 0.12119711935520172\n"
     ]
    }
   ],
   "source": [
    "# Step 3) - Training Loop\n",
    "\n",
    "number_iterations = 200\n",
    "\n",
    "for epoch in range(number_iterations):\n",
    "    # Forward pass / propagation --- Calculate y_predicted\n",
    "    y_predicted = model.forward(X_train)\n",
    "\n",
    "    # Calculate loss using current y_predicted\n",
    "    loss = loss_fn(y_predicted, Y_train)\n",
    "\n",
    "    # Calculate gradient for weights and biases - Backwards Propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights and biases\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch % 10 == 0):\n",
    "        print(f\"epoch = {epoch}, loss = {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5\n",
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8571\n",
      "Recall Score = 0.875\n",
      "Precision Score = 0.8235294117647058\n",
      "F1 Score = 0.8484848484848485\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Model\n",
    "with torch.no_grad():\n",
    "    y_predicted = model.forward(X_test)\n",
    "    y_predicted.round_() # rounds items >= 0.5 to 1, and items < 0.5 to 0\n",
    "\n",
    "    accuracy = y_predicted.eq(Y_test)\n",
    "    accuracy = float(accuracy.sum())\n",
    "\n",
    "    accuracy /= float(Y_test.shape[0]) # Calculating a percentage --- number of correct / number in total\n",
    "    recall = recall_score(y_predicted, Y_test) # tp / (tp + fn)\n",
    "    precision = precision_score(y_predicted, Y_test) # tp / (tp + fp)\n",
    "    f1 = f1_score(y_predicted, Y_test) # f1 score --- reliable measurement because both classes have relatively similar amount of samples ( 51% vs 49% split )\n",
    "    \n",
    "    print(f'Accuracy = {accuracy:.4f}')\n",
    "    print(f'Recall Score = {recall}')\n",
    "    print(f'Precision Score = {precision}') \n",
    "    print(f'F1 Score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With a sample of 20 training loops, \n",
    "##### the mean accuracy is ~85%\n",
    "##### the mean Recall Score is 88%\n",
    "##### the mean Precision Score is 82%\n",
    "##### the mean F1 Score is 84%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Metrics\n",
    "\n",
    "The accuracy is reasonably high, but can be improved by optimizing the hyper parameters of the model, like the random_state passed into the training / testing function call to ensure we train on the most representative sample, as well as the numer of iterations in the training loop to ensure we don't underfit or overfit the model. From rough observations, 200 iterations is when the model performs the best.\n",
    "\n",
    "The Recall Score represents how likely our model will be able to find all true-positives. The high Recall Score indicates that when testing the model against handwriting that is belonging to an Alzheimer's patient, our model will likely be able to correctly detect it as such. Similarly, the Precision Score tells us how reliable a 'positive' from our model actually is-- a decent / medium-to-low may imply that we need to worry about false positives a little. Lastly, the F1 Score describes the holistic reliability of the model, as it's the harmonic mean of the Recall Score and Precision Score. As expected, the average F1 score falls between the average Recall Score and average Precision Score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
